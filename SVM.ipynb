{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f857bc8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[130  36]\n",
      " [ 62 118]]\n",
      "accuracy  0.7167630057803468\n",
      "precision  0.7662337662337663\n",
      "recall   0.6555555555555556\n",
      "f1-measure   0.7065868263473054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Soft\\AppData\\Local\\Temp/ipykernel_18684/4048181062.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  X=data.drop('outcome',1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from sklearn import svm\n",
    "\n",
    "data=pd.read_csv('thefile.csv')\n",
    "X=data.drop('outcome',1)\n",
    "y=data['outcome']\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.3)\n",
    "\n",
    "\n",
    "classifiere =svm.SVC(kernel=\"rbf\")\n",
    "classifiere.fit(x_train,y_train)\n",
    "\n",
    "#prediction \n",
    "predictions = classifiere.predict(x_test)\n",
    "\n",
    "#compare prediction with y_test\n",
    "#confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matrix = confusion_matrix(y_test, predictions)\n",
    "print(matrix)\n",
    "\n",
    "#               PREDICTED\n",
    "#         tn.                  fp\n",
    "#ACTUAL        \n",
    "#         fn                   tp\n",
    "\n",
    "#accuracy score\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc=accuracy_score(y_test,predictions)\n",
    "print(\"accuracy \", acc)\n",
    "\n",
    "#precision\n",
    "from sklearn.metrics import precision_score\n",
    "pre=precision_score(y_test,predictions)\n",
    "print(\"precision \", pre)\n",
    "\n",
    "#recall \n",
    "from sklearn.metrics import recall_score\n",
    "rec=recall_score(y_test,predictions)\n",
    "print(\"recall  \",rec )\n",
    "\n",
    "#f1-measure\n",
    "from sklearn.metrics import f1_score\n",
    "f1=f1_score(y_test,predictions)\n",
    "print(\"f1-measure  \",f1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961ca7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
